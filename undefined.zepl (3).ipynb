{
  "metadata": {
    "name": "Rendimiento",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Adnan Bouaouda Arafa, Sept. 2021, UMA\r\nimport org.apache.flink.api.scala._\r\nimport org.apache.flink.api.scala.utils._\r\nimport org.apache.flink.util.Collector\r\nimport javax.script._\r\nimport scala.annotation.tailrec\r\nimport scalaz._\r\nimport Scalaz._\r\n/**\r\n * Implements the \"eLTL\" logic\r\n */\r\n\r\ntype T // use \"override type\" so specify the type in the user module\r\ndef memoizeFnc[K, V](f: K \u003d\u003e V): K \u003d\u003e V \u003d {\r\nval cache \u003d collection.mutable.Map.empty[K, V]\r\n    k \u003d\u003e\r\n        cache.getOrElse(k, {\r\n        cache update(k, f(k))\r\n        cache(k)\r\n        })\r\n}\r\n\r\ndef apply[T](b: DataSet[(Long, T)], cond: T \u003d\u003e Boolean): DataSet[(Long, Boolean)] \r\n        \u003d  b.map{ e \u003d\u003e (e._1, cond(e._2))}\r\nval mApply \u003d Memo.immutableHashMapMemo{apply _ tupled}\r\n\r\ndef parse[T](b: DataSet[(Long, T)], cond: T \u003d\u003e Boolean): List[Long]\r\n    \u003d { lazy val lazy_b \u003d apply(b, cond).filter{_._2}.map { pair \u003d\u003e pair._1 }.collect.toList\r\n        lazy_b\r\n    }\r\n            \r\ndef intervalPQ(lp: List[Long], lq: List[Long],  ti: Long \u003d 0, tf: Long \u003d Long.MaxValue): List[(Long, Long)] \u003d {\r\ntry{    \r\n    @tailrec def tIntervslPQ(Lp: List[Long], Lq: List[Long], acc: List[(Long, Long)] \u003d List.empty[(Long, Long)]):List[(Long, Long)] \u003d {\r\n        val  Lqq \u003d Lq.dropWhile(_ \u003c\u003d Lp.head)\r\n        val  Lpp \u003d Lp.dropWhile(_ \u003c\u003d Lqq.head)\r\n        (Lpp, Lqq) match {\r\n            case (List(), _) \u003d\u003e acc ++ List((Lp.head, Lqq.head))\r\n            case (_, List()) \u003d\u003e acc ++ List((Lp.head, Lqq.head))\r\n            case (_, _)   \u003d\u003e tIntervslPQ(Lpp, Lqq.tail, acc ++ List((Lp.head, Lqq.head)))\r\n        }\r\n}\r\n    val  lpp \u003d lp.sortWith(_ \u003c _) filter (e \u003d\u003e e \u003e\u003d ti  \u0026\u0026 e\u003c\u003d lq.max)\r\n    val  lqq \u003d lq.sortWith(_ \u003c _) filter (e \u003d\u003e e \u003e\u003d ti  \u0026\u0026 e\u003c\u003d tf)\r\n    tIntervslPQ(lpp, lqq)\r\n}catch{case e: Exception \u003d\u003e List.empty[(Long, Long)]}\r\n} \r\nval mIntervalPQ \u003d Memo.immutableHashMapMemo{intervalPQ _ tupled}\r\ndef intervalP(lp: List[Long],  ti: Long \u003d 0, tf: Long \u003d Long.MaxValue): List[(Long, Long)]\u003d{\r\n    val lpp \u003d lp.sortWith(_ \u003c _) filter (e \u003d\u003e e \u003e\u003d ti  \u0026\u0026 e\u003c\u003d tf)\r\n    lpp zip lpp}\r\nval mIntervalP  \u003d Memo.immutableHashMapMemo{intervalP _ tupled}\r\ndef intervals[T](b: DataSet[(Long, T)], p: T \u003d\u003e Boolean, q: T \u003d\u003e Boolean \u003d null, ti: Long \u003d 0, tf: Long \u003d Long.MaxValue)\r\n\u003d  q match{\r\n        case null \u003d\u003e mIntervalP(parse(b,p), ti, tf)\r\n        case _    \u003d\u003e mIntervalPQ(parse(b,p), parse(b,q), ti, tf)\r\n    }\r\ndef bPQ[T](b: DataSet[(Long, T)], i: List[(Long, Long)])\r\n\u003d i.map(e \u003d\u003e b.filter(x \u003d\u003e (x._1 \u003e\u003d e._1) \u0026\u0026 (x._1 \u003c\u003d e._2)))\r\ndef Phi[T](b: DataSet[(Long, T)], ti: Long \u003d 0, tf: Long \u003d Long.MaxValue): Boolean \u003d ???\r\ndef True[T](b: DataSet[(Long, T)], ti: Long \u003d 0, tf: Long \u003d Long.MaxValue): Boolean \u003d true\r\ndef PhiAll[T](p: T \u003d\u003e Boolean)(b: DataSet[(Long, T)], ti: Long, tf: Long): Boolean \u003d {\r\n        val bb \u003d b.filter(e \u003d\u003e (e._1 \u003e\u003d ti) \u0026\u0026 (e._1 \u003c\u003d tf))\r\n        bb.map(e \u003d\u003e p(e._2)).collect.forall(_ \u003d\u003d true)\r\n}\r\ndef PhiK[T](K: Long)(p: T \u003d\u003e Boolean, q: T \u003d\u003e Boolean \u003d null)\r\n    \u003d {(b: DataSet[(Long, T)], ti: Long, tf: Long) \r\n    \u003d\u003e intervals(b, p, q, ti, tf).map(e \u003d\u003e (e._2 - e._1 \u003e\u003d K)).\r\n    reduceOption(_ || _).getOrElse(false)}\r\ndef Neg[T](F: (DataSet[(Long, T)], Long, Long) \u003d\u003e Boolean)\r\n    \u003d{(b: DataSet[(Long, T)], ti: Long, tf: Long) \u003d\u003e !F(b, ti, tf)}\r\ndef Or[T](F1: (DataSet[(Long, T)], Long, Long) \u003d\u003e Boolean, \r\n        F2: (DataSet[(Long, T)], Long, Long) \u003d\u003e Boolean)\r\n    \u003d {(b: DataSet[(Long, T)], ti: Long, tf: Long) \r\n    \u003d\u003e F1(b, ti, tf) || F2(b, ti, tf)}  \r\ndef U[T](p: T \u003d\u003e Boolean, q: T \u003d\u003e Boolean \u003d null)\r\n    (F1: (DataSet[(Long, T)], Long, Long) \u003d\u003e Boolean,\r\n    F2: (DataSet[(Long, T)], Long, Long) \u003d\u003e Boolean)\r\n    \u003d {(b: DataSet[(Long, T)], ti: Long, tf: Long)\r\n    \u003d\u003e intervals(b, p, q, ti, tf).map(e \u003d\u003e F1(b, ti, e._1) \u0026\u0026 F2(b, e._1, e._2)).\r\n    reduceOption(_ || _).getOrElse(false)}                                 \r\ndef E[T](p: T \u003d\u003e Boolean, q: T \u003d\u003e Boolean \u003d null)\r\n    (F: (DataSet[(Long, T)], Long, Long) \u003d\u003e Boolean)\r\n    \u003d {(b: DataSet[(Long, T)], ti: Long, tf: Long) \r\n    \u003d\u003e  val I \u003d intervals(b, p, q, ti, tf); I.map(e \u003d\u003e F(b, e._1, e._2)).\r\n    reduceOption(_ || _).getOrElse(false)}\r\ndef E2[T](p: T \u003d\u003e Boolean, q: T \u003d\u003e Boolean \u003d null)\r\n        (F: (DataSet[(Long, T)], Long, Long) \u003d\u003e Boolean)  \u003d U(p, q)(True, F)\r\ndef A[T](p: T \u003d\u003e Boolean, q: T \u003d\u003e Boolean \u003d {(e: T) \u003d\u003e true})\r\n        (F: (DataSet[(Long, T)], Long, Long) \u003d\u003e Boolean)\r\n    \u003d {(b: DataSet[(Long, T)], ti: Long, tf: Long)\r\n    \u003d\u003e  val I \u003d intervals(b, p, q, ti, tf); I.map(e \u003d\u003e F(b, e._1, e._2)).\r\n        reduceOption(_ \u0026\u0026 _).getOrElse(false)}\r\ndef A2[T](p: T \u003d\u003e Boolean, q: T \u003d\u003e Boolean \u003d null)\r\n        (F: (DataSet[(Long, T)], Long, Long) \u003d\u003e Boolean)  \u003d Neg(E(p, q)(Neg(F)))\r\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%sh\ncat ./csv/10.csv"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "type T \u003d (Long, Int)\r\ntype TT \u003d Int\r\nval path \u003d os.pwd / \"csv\"\r\n\r\nval _10      \u003d benv.readCsvFile[T](path+\"/10.csv\", fieldDelimiter \u003d \";\")\r\n\r\ndef Start: (TT \u003d\u003e Boolean) \u003d (e: TT) \u003d\u003e {e \u003d\u003d 1}\r\ndef Stop : (TT \u003d\u003e Boolean) \u003d (e: TT) \u003d\u003e {e \u003d\u003d 3}\r\ndef Cond : (TT \u003d\u003e Boolean) \u003d (e: TT) \u003d\u003e {e \u003d\u003d 2}\r\n\r\nprintln(A(Start, Stop) (E(Cond) (True)) (_10, 0, Long.MaxValue))"
    }
  ]
}